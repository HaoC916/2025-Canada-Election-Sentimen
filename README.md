# ğŸ‡¨ğŸ‡¦ Election Sentiment 2025  
### *CMPT 732 â€” Big Data Final Project*

This project analyzes **Canadian political sentiment** across Reddit and compares it with **federal election polling trends**.  
We implement:

- **Baseline method** â€” Targeted VADER sentiment
- **Advanced method** â€” Transformer-based sentiment (RoBERTa)
- **Time-series analysis** â€” Weekly sentiment per party  
- **Correlation analysis** â€” Sentiment vs polling numbers

The final output:  
**A complete pipeline that downloads â†’ cleans â†’ processes â†’ aggregates â†’ merges â†’ visualizes**.

---

# ğŸ“ Project Structure

```
election-sentiment-2025/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sentiment_daily/
â”‚   â”œâ”€â”€ sentiment_daily_updated_key/
â”‚   â”œâ”€â”€ sentiment_weekly/
â”‚   â”œâ”€â”€ sentiment_weekly_updated_key/
â”‚   â”œâ”€â”€ polling_averages.txt
â”‚   â”œâ”€â”€ probability_winning.txt
â”‚   â””â”€â”€  vader_tran_scored_sample.json
â”‚
â”œâ”€â”€ ETL/
â”‚   â”œâ”€â”€ filter_comments_zst.py       # Step 1a: RC_YYYY-MM.zst â†’ filtered JSONL
â”‚   â”œâ”€â”€ filter_submissions_zst.py    # Step 1b: RS_YYYY-MM.zst â†’ filtered JSONL
â”‚   â”œâ”€â”€ comments_filter.py           # Step 2a: Spark comment cleanup
â”‚   â”œâ”€â”€ submissions_filter.py        # Step 2b: Spark submission cleanup
â”‚   â”œâ”€â”€ join_titles.py               # Step 2c: Join comments + submission titles
â”‚   â””â”€â”€ logs.txt
â”‚
â”œâ”€â”€ sentiment/
â”‚   â”œâ”€â”€ extract_party_sentences.py   # Step 3a: Extract targeted sentences per party
â”‚   â”œâ”€â”€ add_trans_sentiment.py       # Step 3b: Transformer (RoBERTa) scoring
â”‚   â””â”€â”€ baseline_vader.py            # Step 3c: VADER scoring
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ data_aggregation.py          # Step 4a: Weekly/daily aggregation
â”‚   â”œâ”€â”€ correlation_analysis.py      # Step 4b: Sentimentâ€“polling correlation
â”‚   â”œâ”€â”€ dashboard.py                 # Front-end: Streamlit dashboard
â”‚   â””â”€â”€ sample_scored.py
â”‚
â””â”€â”€ results/
    â”œâ”€â”€ vader_targeted/
    â”œâ”€â”€ transformer/
    â”œâ”€â”€ sentiment_daily/
    â”œâ”€â”€ sentiment_weekly/
    â”œâ”€â”€ merged/
    â””â”€â”€ figures/
```

---

# âš™ï¸ Installation

```
pip install -r requirements.txt
```

---

# ğŸ§ª Quick Test
If you want to verify functionality without re-running Steps 1â€“3,
all they need to run is:
```
python analysis/data_aggregation.py
python analysis/correlation_analysis.py
streamlit run analysis/dashboard.py
```
All of these use the sample data stored inside data/.

# ğŸš€ Running the Full Pipeline

## 0. (Optional) Skip ETL â€” Download Pre-Joined Reddit Data

If you do NOT want to process 1.2 billion Reddit comments yourself,
you can directly download our joined & cleaned ETL output (2025-01 to 2025-04):

ğŸ“¦ Google Drive (recommended):
ğŸ‘‰ https://drive.google.com/drive/folders/1BAYBEI2GYo1UPVWAQ_4IhW0m4GPKUKmi

This contains four folders:

2025-01.zip
2025-02.zip
2025-03.zip
2025-04.zip

Each ZIP contains:

joined_rdd/YYYY-MM/
    part-*.json

If you download these files, you may skip all ETL steps (step 1 & 2) and jump directly to:

â¡ sentiment/extract_party_sentences.py

---

## 1. ETL - Fast Pre-Filtering
If you prefer to reproduce the ETL pipeline from scratch,
you must first download raw Reddit dumps (Januaryâ€“April 2025):

ğŸ“¥ Original Reddit RC/RS Data (Academic Torrents):
https://academictorrents.com/details/30dee5f0406da7a353aff6a8caa2d54fd01f2ca1

Required files (8 total):

RC_2025-01.zst
RC_2025-02.zst
RC_2025-03.zst
RC_2025-04.zst
RS_2025-01.zst
RS_2025-02.zst
RS_2025-03.zst
RS_2025-04.zst


The ETL step requires running five scripts manually, each with input and output paths.

All commands follow this structure:
python script.py <input_path> <output_path>
spark-submit script.py <input_path> <output_path>


ğŸ”¹ Step 1a â€” Filter raw Reddit comments (.zst â†’ filtered JSONL)
```
python ETL/filter_comments_zst.py <raw_comments_zst> <filtered_output_json>
```

Example:
```
python ETL/filter_comments_zst.py \
    /Users/ryan/datasets/reddit/comments/RC_2025-01.zst \
    /Users/ryan/datasets/reddit/comments/RC_2025-01_filtered.json
```

ğŸ”¹ Step 1b â€” Filter raw Reddit submissions (.zst â†’ filtered JSONL)
```
python ETL/filter_submissions_zst.py <raw_submissions_zst> <filtered_output_json>
```

Example:
```
python ETL/filter_submissions_zst.py \
    /Users/ryan/datasets/reddit/submissions/RS_2025-01.zst \
    /Users/ryan/datasets/reddit/submissions/RS_2025-01_filtered.json
```

---

## 2. ETL - Spark ETL
ğŸ”¹ Step 2a â€” Spark cleaning of comments
```
spark-submit ETL/comments_filter.py <filtered_comments_json> <cleaned_output_dir>
```

Example:
```
spark-submit ETL/comments_filter.py \
    /Users/ryan/datasets/reddit/comments/RC_2025-01_filtered.json \
    /Users/ryan/datasets/reddit/cleaned/comments/2025-01
```

ğŸ”¹ Step 2b â€” Spark cleaning of submissions
```
spark-submit ETL/submissions_filter.py <filtered_submissions_json> <cleaned_output_dir>
```

Example:
```
spark-submit ETL/submissions_filter.py \
    /Users/ryan/datasets/reddit/submissions/RS_2025-01_filtered.json \
    /Users/ryan/datasets/reddit/cleaned/submissions/2025-01
```

ğŸ”¹ Step 2c â€” Join comments with submission titles
```
spark-submit ETL/join_titles.py <cleaned_comments_dir> <cleaned_submissions_dir> <joined_output_dir>
```

Example:
```
spark-submit ETL/join_titles.py \
    /Users/ryan/datasets/reddit/cleaned/comments/2025-01 \
    /Users/ryan/datasets/reddit/cleaned/submissions/2025-01 \
    /Users/ryan/datasets/reddit/joined/2025-01
```

---

## 3. Sentiment

ğŸ“¦ (Optional) Skip Step 3 â€” Download Pre-Computed Sentiment Data

If you do NOT want to rerun the Transformer/VADER scoring (very slow without GPU),
download our pre-computed Step 3 output from Google Drive:

ğŸ‘‰ https://drive.google.com/file/d/1bXJ_JlQu_xzUsRbajEGasY8UCPJ51-57/view?usp=drive_link 

ğŸ”¹ Step 3a â€” Extract Party Sentences

```
spark-submit sentiment/extract_party_sentences.py <joined_input_dir> <party_target_dir>
```

Example:
```
spark-submit sentiment/extract_party_sentences.py \
    "/Users/ryan/datasets/reddit/joined/2025-*" \
    "/Users/ryan/datasets/reddit/party_target/2025"
```

ğŸ”¹ Step 3b â€” Extract Party Sentences
```
python sentiment/add_trans_sentiment.py <party_target_dir> <trans_sentiment_output_dir>
```

Example:
```
python sentiment/add_trans_sentiment.py \
    /Users/ryan/datasets/reddit/party_target/ \
    /Users/ryan/datasets/reddit/trans_sentiment/
```

ğŸ”¹ Step 3c â€” Baseline Vader
```
python sentiment/baseline_vader.py <trans_scored_dir> <vader_output_dir>
```

Example:
```
python sentiment/baseline_vader.py \
    /Users/ryan/datasets/reddit/trans_sentiment/2025 \
    /Users/ryan/datasets/reddit/vader_sentiment/2025
```
---

## 4. Analysis
This stage performs:

Weekly & Daily sentiment aggregation (Transformer + VADER)

Correlation analysis against Canadian polling data

Regression modeling

Visualization (heatmaps + regression plots)

Interactive dashboard using Streamlit

You can run the analysis on either:

Your own computed sentiment outputs (from Step 3), OR

Our sample dataset included in data/ (recommended for quick testing).

ğŸ”¹ Step 4a â€” Weekly & Daily Aggregation

```
python analysis/data_aggregation.py
```

Input used by default:
```
data/vader_tran_scored_sample.json
```

Outputs:
```
results/sentiment_weekly_updated_key/
results/sentiment_daily_updated_key/
```
These files become inputs for Step 4b.

ğŸ”¹ Step 4b Sentimentâ€“Polling Correlation Analysis     
```
python analysis/correlation_analysis.py
```

This step:

Computes Pearson & Spearman correlations

Computes lag correlations

Fits OLS regressions

Saves all visualizations to:

```
results/plots_old/
```

and logs printed output to:
```
results/output_log_old.txt
```

ğŸ”¹ Step 4c â€” Interactive Dashboard (Streamlit)

To view the web-based dashboard:
```
streamlit run analysis/dashboard.py
```

Once running, open:

ğŸ‘‰ http://localhost:8501

The dashboard includes:

Weekly sentiment trends

Daily sentiment trends

Party comparisons

Correlation visualizations

Volume statistics

Transformer vs VADER comparison

---

# ğŸ‘¥ Authors
[][][]
CMPT 732 Group â€” Fall 2025  
SFU School of Computing Science
